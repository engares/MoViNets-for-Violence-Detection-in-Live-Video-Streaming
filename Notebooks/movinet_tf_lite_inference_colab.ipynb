{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcGMdB0Es_BL"
      },
      "source": [
        "## Importing Modules"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/engares/MoViNets-for-Violence-Detection-in-Live-Video-Streaming.git"
      ],
      "metadata": {
        "id": "EnLIm8dOkJkx",
        "outputId": "dd516ec4-aae2-4408-b1f8-d542e4e1cffa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MoViNets-for-Violence-Detection-in-Live-Video-Streaming'...\n",
            "remote: Enumerating objects: 398, done.\u001b[K\n",
            "remote: Counting objects: 100% (172/172), done.\u001b[K\n",
            "remote: Compressing objects: 100% (85/85), done.\u001b[K\n",
            "remote: Total 398 (delta 93), reused 162 (delta 86), pack-reused 226\u001b[K\n",
            "Receiving objects: 100% (398/398), 57.37 MiB | 12.79 MiB/s, done.\n",
            "Resolving deltas: 100% (126/126), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install pkg-config libhdf5-dev"
      ],
      "metadata": {
        "id": "0W0EknUwSxFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r ./MoViNets-for-Violence-Detection-in-Live-Video-Streaming/requeriments_tflite.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yS7TrZJntHGF",
        "outputId": "f96c8681-c7c3-4df5-8820-3d87f61825e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: './MoViNets-for-Violence-Detection-in-Live-Video-Streaming/requeriments_arm64.txt'\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "NIgXAVdMs_BN"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Some modules to display an animation using imageio.\n",
        "import imageio\n",
        "\n",
        "import tflite_runtime.interpreter as tflite\n",
        "import tensorflow as tf\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "291F7rCas_BP"
      },
      "source": [
        "## Building the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "e0qMEdyNs_BR"
      },
      "outputs": [],
      "source": [
        "# Create the interpreter and signature runner\n",
        "tflite_filename = './model.tflite'\n",
        "\n",
        "interpreter = tf.lite.Interpreter(model_path=tflite_filename)\n",
        "runner = interpreter.get_signature_runner()\n",
        "\n",
        "init_states = {\n",
        "    name: tf.zeros(x['shape'], dtype=x['dtype'])\n",
        "    for name, x in runner.get_input_details().items()\n",
        "}\n",
        "del init_states['image']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-BqOX5ts_BR"
      },
      "source": [
        "### Inference on Streaming"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def to_gif(images,path = './animation.gif' ):\n",
        "  converted_images = np.clip(images * 244, 0, 244).astype(np.uint8)\n",
        "  imageio.mimsave(path, converted_images, fps=5)\n",
        "  return embed.embed_file(path)\n",
        "\n",
        "def frames_from_video_file(video_path, n_frames, output_size = (224,224), frame_step = 15):\n",
        "  \"\"\"\n",
        "    Creates frames from each video file present for each category.\n",
        "\n",
        "    Args:\n",
        "      video_path: File path to the video.\n",
        "      n_frames: Number of frames to be created per video file.\n",
        "      output_size: Pixel size of the output frame image.\n",
        "\n",
        "    Return:\n",
        "      An NumPy array of frames in the shape of (n_frames, height, width, channels).\n",
        "  \"\"\"\n",
        "  # Read each video frame by frame\n",
        "  result = []\n",
        "  src = cv2.VideoCapture(str(video_path))\n",
        "\n",
        "  video_length = src.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "\n",
        "  need_length = 1 + (n_frames - 1) * frame_step\n",
        "\n",
        "  if need_length > video_length:\n",
        "    start = 0\n",
        "  else:\n",
        "    max_start = video_length - need_length\n",
        "    start = random.randint(0, max_start + 1)\n",
        "\n",
        "  src.set(cv2.CAP_PROP_POS_FRAMES, start)\n",
        "  # ret is a boolean indicating whether read was successful, frame is the image itself\n",
        "  ret, frame = src.read()\n",
        "  result.append(format_frames(frame, output_size))\n",
        "\n",
        "  for _ in range(n_frames - 1):\n",
        "    for _ in range(frame_step):\n",
        "      ret, frame = src.read()\n",
        "    if ret:\n",
        "      frame = format_frames(frame, output_size)\n",
        "      result.append(frame)\n",
        "    else:\n",
        "      result.append(np.zeros_like(result[0]))\n",
        "  src.release()\n",
        "  result = np.array(result)[..., [2, 1, 0]]\n",
        "\n",
        "  return result\n",
        "\n",
        "def format_frames(frame, output_size):\n",
        "  \"\"\"\n",
        "    Pad and resize an image from a video.\n",
        "\n",
        "    Args:\n",
        "      frame: Image that needs to resized and padded.\n",
        "      output_size: Pixel size of the output frame image.\n",
        "\n",
        "    Return:\n",
        "      Formatted frame with padding of specified output size.\n",
        "  \"\"\"\n",
        "  frame = tf.image.convert_image_dtype(frame, tf.float32)\n",
        "  frame = tf.image.resize_with_pad(frame, *output_size)\n",
        "  return frame\n",
        "\n",
        "def video_to_gif_tensor(video_path, image_size=(224, 224), fps=12):\n",
        "    \"\"\"\n",
        "    Processes frames from a video file, saves them as a GIF in the same directory, and loads the GIF as a TensorFlow tensor.\n",
        "\n",
        "    Args:\n",
        "      video_path: String path to the input video file.\n",
        "      image_size: Tuple indicating the size to which each frame should be resized.\n",
        "      fps: Frames per second to be used in the GIF.\n",
        "\n",
        "    Returns:\n",
        "      A TensorFlow tensor representing the loaded GIF.\n",
        "    \"\"\"\n",
        "    # Generate the gif_path in the same directory with a .gif extension\n",
        "    gif_path = os.path.splitext(video_path)[0] + '.gif'\n",
        "\n",
        "    # Assume frames_from_video_file is a function that extracts frames from video\n",
        "    images = frames_from_video_file(video_path, n_frames=fps)  # function to be defined or replaced\n",
        "\n",
        "    # Convert images to uint8 and save as GIF\n",
        "    converted_images = np.clip(images * 255, 0, 255).astype(np.uint8)  # Proper scaling to 255\n",
        "    imageio.mimsave(gif_path, converted_images, fps=fps)\n",
        "\n",
        "    # Load the GIF file into a TensorFlow tensor\n",
        "    raw = tf.io.read_file(gif_path)\n",
        "    video = tf.io.decode_gif(raw)\n",
        "    video = tf.image.resize(video, image_size)\n",
        "    video = tf.cast(video, tf.float32) / 255.0  # Normalize to [0,1]\n",
        "\n",
        "    return video\n",
        "\n",
        "CLASSES = ['Fight','No_Fight']\n",
        "\n",
        "def get_top_k(probs, k=2, label_map=CLASSES):\n",
        "  \"\"\"Outputs the top k model labels and probabilities on the given video.\"\"\"\n",
        "  top_predictions = tf.argsort(probs, axis=-1, direction='DESCENDING')[:k]\n",
        "  top_labels = tf.gather(label_map, top_predictions, axis=-1)\n",
        "  top_labels = [label.decode('utf8') for label in top_labels.numpy()]\n",
        "  top_probs = tf.gather(probs, top_predictions, axis=-1).numpy()\n",
        "  return tuple(zip(top_labels, top_probs))\n"
      ],
      "metadata": {
        "id": "49Y8o-0XN9sl"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Insert your video clip here\n",
        "\n",
        "video = video_to_gif_tensor('./MoViNets-for-Violence-Detection-in-Live-Video-Streaming/test_videos/tf_X7GtOGyE_0.avi', image_size=(172, 172))\n",
        "clips = tf.split(video[tf.newaxis], video.shape[0], axis=1)\n",
        "\n",
        "# To run on a video, pass in one frame at a time\n",
        "states = init_states\n",
        "for clip in clips:\n",
        "  # Input shape: [1, 1, 172, 172, 3]\n",
        "  outputs = runner(**states, image=clip)\n",
        "  logits = outputs.pop('logits')[0]\n",
        "  states = outputs\n",
        "\n",
        "probs = tf.nn.softmax(logits)\n",
        "top_k = get_top_k(probs)\n",
        "print()\n",
        "for label, prob in top_k:\n",
        "  print(label, prob)\n",
        "\n"
      ],
      "metadata": {
        "id": "qPjwqrJ6OIwL",
        "outputId": "a5fcc85e-d820-4099-c225-e954a748a069",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fight 0.5970546\n",
            "No_Fight 0.40294543\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}